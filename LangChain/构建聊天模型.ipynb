{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41b01cd7",
   "metadata": {},
   "source": [
    "### 环境要求\n",
    "\n",
    "python 3.12 与最新 langchain 存在兼容问题，所以降级安装3.9版本\n",
    "\n",
    "```cmd\n",
    "conda create -n .venv python=3.9\n",
    "conda activate .venv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f38cf4",
   "metadata": {},
   "source": [
    "### 安装依赖\n",
    "```cmd\n",
    "conda install ipykernel  // jupyter notebook 需要\n",
    "conda install python-dotenv -c conda-forge \n",
    "conda install langchain -c conda-forge \n",
    "conda install langchain-community -c conda-forge\n",
    "conda install langchain-openai -c conda-forge\n",
    "conda install openai -c conda-forge\n",
    "conda install tiktoken -c conda-forge  // 对话字符缓存使用\n",
    "conda install pandas -c conda-forge   // 读取 csv 数据\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1734ec57",
   "metadata": {},
   "source": [
    "### 通过 LangChain 使用 OpenAI\n",
    "三个重要的概念：模型、提示与解释器\n",
    "#### 模型\n",
    "从 `langchain.chat_models`导入`OpenAI`的对话模型`ChatOpenAI`，除了`OpenAI` 以外，`chat_models`也集成了其它的对话模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0a6ef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# 配置了环境变量，删除项目内的环境变量配置\n",
    "# import os\n",
    "# from dotenv import load_dotenv, find_dotenv\n",
    "# _ = load_dotenv(find_dotenv())\n",
    "\n",
    "\n",
    "# # 获取环境变量\n",
    "# api_key = os.environ[\"OPENAI_API_KEY_LOCAL\"]\n",
    "# base_url = os.environ[\"OPENAI_BASE_URL\"]\n",
    "\n",
    "# 这里我们将参数temperature设置为0.0，从而减少生成答案的随机性。\n",
    "# 如果你想要每次得到不一样的有新意的答案，可以尝试调整该参数。\n",
    "chat = ChatOpenAI(temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db72fb86",
   "metadata": {},
   "source": [
    "#### 提示模板\n",
    "在应用于比较复杂的场景时，提示可能会非常长并且包含涉及许多细节。使用提示模版，可以让我们更为方便地重复使用设计好的提示。\n",
    "LangChain还提供了提示模版用于一些常用场景。比如自动摘要、问答、连接到SQL数据库、连接到不同的API。通过使用LangChain内置的提示模版，你可以快速建立自己的大模型应用，而不需要花时间去设计和构造提示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f3f51c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['style', 'text'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['style', 'text'], template='把由三个反引号分隔的文本翻译成一种{style}风格。文本: ```{text}```\\n'))]\n",
      "[HumanMessage(content='把由三个反引号分隔的文本翻译成一种正式普通话 用一个平静、尊敬的语气\\n风格。文本: ```\\n有人违法使用我的电话信息，请马上注销，不然我将投诉12315/信息安全局以及曝光，请2小时马上答复我。\\n```\\n')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/.venv/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "尊敬的相关部门，我发现有人违法使用了我的电话信息，请立即注销。如果不立即处理，我将不得不向12315/信息安全局投诉并曝光此事。请在两小时内给予答复，谢谢。\n"
     ]
    }
   ],
   "source": [
    "# 编写 prompt\n",
    "template_string = \"\"\"把由三个反引号分隔的文本\\\n",
    "翻译成一种{style}风格。\\\n",
    "文本: ```{text}```\n",
    "\"\"\"\n",
    "\n",
    "# 然后，我们调用`ChatPromptTemplatee.from_template()`函数将\n",
    "# 上面的提示模版字符`template_string`转换为提示模版`prompt_template`\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "\n",
    "print(prompt_template)\n",
    "\n",
    "customer_style = \"\"\"正式普通话 \\\n",
    "用一个平静、尊敬的语气\n",
    "\"\"\"\n",
    "\n",
    "customer_email = \"\"\"\n",
    "有人违法使用我的电话信息，请马上注销，不然我将投诉12315/信息安全局以及曝光，请2小时马上答复我。\n",
    "\"\"\"\n",
    "\n",
    "# 使用提示模版\n",
    "customer_messages = prompt_template.format_messages(\n",
    "    style=customer_style, text=customer_email\n",
    ")\n",
    "\n",
    "print(customer_messages)\n",
    "\n",
    "customer_response = chat(customer_messages)\n",
    "print(customer_response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c05fc2b",
   "metadata": {},
   "source": [
    "#### 输出解释器\n",
    "以上`customer_response`输出为 `str` 类型，如果想要方便的提取信息，需要使用`Langchain`中的输出解释器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0976e517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出格式规定： The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"语气\": string  // 语气是否平和\n",
      "\t\"语言风格\": string  // 语言风格是否正式\n",
      "}\n",
      "```\n",
      "结果类型: <class 'str'>\n",
      "```json\n",
      "{\n",
      "\t\"语气\": \"激动\"  // 语气是否平和\n",
      "\t\"语言风格\": \"正式\"  // 语言风格是否正式\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "\n",
    "template_string = \"\"\"\n",
    "对于以下文本，提取出以下信息：\n",
    "\n",
    "语气：语气是否平和\n",
    "\n",
    "语言风格：语言风格是否正式\n",
    "\n",
    "使用以下键将输出格式化为 JSON：\n",
    "语气\n",
    "语言风格\n",
    "\n",
    "\n",
    "文本：{text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "\n",
    "response_schemas  = [\n",
    "  ResponseSchema(name=\"语气\", description=\"语气是否平和\"),\n",
    "  ResponseSchema(name=\"语言风格\", description=\"语言风格是否正式\")\n",
    "]\n",
    "\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(\"输出格式规定：\",format_instructions)\n",
    "\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "有人违法使用我的电话信息，请马上注销，不然我将投诉12315/信息安全局以及曝光，请2小时马上答复我。\n",
    "\"\"\"\n",
    "\n",
    "# 使用提示模版\n",
    "message = prompt_template.format_messages(text=text, format_instructions=format_instructions)\n",
    "\n",
    "customer_response = chat(message)\n",
    "print(\"结果类型:\", type(customer_response.content))\n",
    "print(customer_response.content)\n",
    "\n",
    "# output_dict = output_parser.parse(customer_response.content)\n",
    "# print(\"解析后的结果类型:\", type(output_dict))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dd5af1",
   "metadata": {},
   "source": [
    "### 储存 Memory\n",
    "使用 LangChain 中的储存(Memory)模块时，它旨在保存、组织和跟踪整个对话的历史，从而为用户和模型之间的交互提供连续的上下文。\n",
    "\n",
    "LangChain 提供了多种储存类型。其中:\n",
    "* 缓冲区储存允许保留最近的聊天消息\n",
    "* 摘要储存则提供了对整个对话的摘要。\n",
    "* 实体储存则允许在多轮对话中保留有关特定实体的信息。\n",
    "\n",
    "这些记忆组件都是模块化的，可与其他组件组合使用，从而增强机器人的对话管理能力。\n",
    "\n",
    "主要的 4 种存储模块：\n",
    "* 对话缓存储存 (ConversationBufferMemory）\n",
    "* 对话缓存窗口储存 (ConversationBufferWindowMemory）\n",
    "* 对话令牌缓存储存 (ConversationTokenBufferMemory）\n",
    "* 对话摘要缓存储存 (ConversationSummaryBufferMemory）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2972d5e4",
   "metadata": {},
   "source": [
    "#### 对话缓存存储\n",
    "属于缓冲区储存器，用于存储对话上下文信息，包括历史消息、当前消息、历史消息的embedding等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02039041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# 这里我们将参数temperature设置为0.0，从而减少生成答案的随机性。\n",
    "# 如果你想要每次得到不一样的有新意的答案，可以尝试增大该参数。\n",
    "llm = ChatOpenAI(temperature=0.0, api_key=api_key, base_url=base_url)\n",
    "memory = ConversationBufferMemory()\n",
    "memory.save_context({\"input\": \"你好，我叫皮皮鲁\"}, {\"output\": \"你好啊，我叫鲁西西\"})\n",
    "\n",
    "# 新建一个 ConversationChain Class 实例\n",
    "# verbose参数设置为True时，程序会输出更详细的信息，以提供更多的调试或运行时信息。\n",
    "# 相反，当将verbose参数设置为False时，程序会以更简洁的方式运行，只输出关键的信息。\n",
    "conversation = ConversationChain(llm=llm, memory = memory, verbose=True )\n",
    "\n",
    "conversation.predict(input=\"你好, 我叫池\")\n",
    "conversation.predict(input=\"1+1 等于几\")\n",
    "conversation.predict(input=\"我叫什么\")\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f9759e",
   "metadata": {},
   "source": [
    "#### 对话窗口存储\n",
    "对话缓存窗口储存只保留一个窗口大小的对话。它只使用最近的n次交互。这可以用于保持最近交互的滑动窗口，以便缓冲区不会过大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e377104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "# k=1表明只保留一个对话记忆\n",
    "memory = ConversationBufferWindowMemory(k=1)  \n",
    "\n",
    "llm = ChatOpenAI(temperature=0.0, api_key=api_key, base_url=base_url)\n",
    "conversation = ConversationChain(llm=llm, memory=memory, verbose=False  )\n",
    "\n",
    "print(\"第一轮对话：\")\n",
    "print(conversation.predict(input=\"你好, 我叫池\"))\n",
    "\n",
    "print(\"第二轮对话：\")\n",
    "print(conversation.predict(input=\"我叫什么名字？\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1766adb2",
   "metadata": {},
   "source": [
    "#### 对话字符缓存存储\n",
    "使用对话字符缓存记忆，内存将限制保存的token数量。如果字符数量超出指定数目，它会切掉这个对话的早期部分 以保留与最近的交流相对应的字符数量，但不超过字符限制。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64698a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)\n",
    "memory.save_context({\"input\": \"朝辞白帝彩云间，\"}, {\"output\": \"千里江陵一日还。\"})\n",
    "memory.save_context({\"input\": \"两岸猿声啼不住，\"}, {\"output\": \"轻舟已过万重山。\"})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c031801",
   "metadata": {},
   "source": [
    "### 模型链 Chains\n",
    "链（Chains）通常将大语言模型（LLM）与提示（Prompt）结合在一起，基于此，我们可以对文本或数据进行一系列操作。链（Chains）可以一次性接受多个输入。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b466eeb6",
   "metadata": {},
   "source": [
    "#### 简单顺序链\n",
    "预定义顺序执行其链接的链，其中每个步骤都有一个输入/输出，一个步骤的输出是下一个步骤的输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4643e8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\"Royal Linens\"\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mRoyal Linens：提供高质量的床上用品和家居装饰产品。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Royal Linens：提供高质量的床上用品和家居装饰产品。'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI \n",
    "from langchain.prompts import ChatPromptTemplate  \n",
    "from langchain.chains import LLMChain,SimpleSequentialChain\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.0, api_key=api_key, base_url=base_url)\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_template(\"描述制造{product}的一个公司的最佳名称是什么?\")\n",
    "\n",
    "# chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "\n",
    "# 提示模板 1 ：这个提示将接受产品并返回最佳名称来描述该公司\n",
    "first_prompt = ChatPromptTemplate.from_template(   \n",
    "    \"描述制造{product}的一个公司的最好的名称是什么\"\n",
    ")\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)\n",
    "\n",
    "# 提示模板 2 ：接受公司名称，然后输出该公司的长为20个单词的描述\n",
    "second_prompt = ChatPromptTemplate.from_template(   \n",
    "    \"写一个10字的描述对于下面这个\\\n",
    "    公司：{company_name}的\"\n",
    ")\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)\n",
    "\n",
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two], verbose=True)\n",
    "\n",
    "product = \"大号床单套装\"\n",
    "overall_simple_chain.run(product)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce57265",
   "metadata": {},
   "source": [
    "#### 多输入、输出顺序链\n",
    "当只有一个输入和一个输出时，简单顺序链（SimpleSequentialChain）即可实现。当有多个输入或多个输出时，我们则需要使用顺序链（SequentialChain）来实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e13b137a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.chat_models import ChatOpenAI    #导入OpenAI模型\n",
    "from langchain.prompts import ChatPromptTemplate   #导入聊天提示模板\n",
    "from langchain.chains import LLMChain    #导入LLM链。\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.9, api_key=api_key, base_url=base_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1434f6e",
   "metadata": {},
   "source": [
    "创建 4 个子链"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "528b7ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#子链1\n",
    "# prompt模板 1: 翻译成英语（把下面的review翻译成英语）\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"把下面的水果review翻译成英文:\"\n",
    "    \"\\n\\n{Review}\"\n",
    ")\n",
    "# chain 1: 输入：Review    输出：英文的 Review\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, output_key=\"English_Review\")\n",
    "\n",
    "#子链2\n",
    "# prompt模板 2: 用一句话总结下面的 review\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"请你用一句话来描述下面的review:\"\n",
    "    \"\\n\\n{English_Review}\"\n",
    ")\n",
    "# chain 2: 输入：英文的Review   输出：总结\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, output_key=\"summary\")\n",
    "\n",
    "\n",
    "#子链3\n",
    "# prompt模板 3: 下面review使用的什么语言\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"下面的review使用的什么语言:\\n\\n{Review}\"\n",
    ")\n",
    "# chain 3: 输入：Review  输出：语言\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt, output_key=\"language\")\n",
    "\n",
    "\n",
    "#子链4\n",
    "# prompt模板 4: 使用特定的语言对下面的总结写一个后续回复\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"使用特定的语言对下面的总结写一个后续回复:\"\n",
    "    \"\\n\\n总结: {summary}\\n\\n语言: {language}\"\n",
    ")\n",
    "# chain 4: 输入： 总结, 语言    输出： 后续回复\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt, output_key=\"followup_message\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d804d074",
   "metadata": {},
   "source": [
    "组合四个子链"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a3bf0345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Review': '苹果',\n",
       " 'English_Review': 'Apple\\n\\nThe apple is a popular and versatile fruit that is enjoyed by people of all ages. It is crisp and juicy, with a sweet and slightly tart flavor. Apples can be eaten on their own as a healthy snack, or used in a variety of dishes such as pies, crisps, and salads. They are also a good source of fiber and vitamin C, making them a nutritious choice for any diet. Overall, apples are a delicious and refreshing fruit that can be enjoyed year-round.',\n",
       " 'summary': 'Apples are a delicious and versatile fruit that can be enjoyed in many different ways and are a nutritious choice for any diet.',\n",
       " 'followup_message': '谢谢你的总结!苹果是一种美味多样、可以用多种方式享用的水果，不仅适合任何饮食，而且营养丰富。我也喜欢吃苹果，它们是我日常饮食的重要组成部分。你有什么喜欢的苹果食谱吗？分享给我们吧!'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#输入：review    \n",
    "#输出：英文review，总结，后续回复 \n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"Review\"],\n",
    "    output_variables=[\"English_Review\", \"summary\",\"followup_message\"],\n",
    "    verbose=True\n",
    ")\n",
    "review = \"苹果\"\n",
    "overall_chain(review)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdc2262",
   "metadata": {},
   "source": [
    "#### 路由链\n",
    "一个相当常见但基本的操作是根据输入将其路由到一条链，具体取决于该输入到底是什么。如果你有多个子链，每个子链都专门用于特定类型的输入，那么可以组成一个路由链，它首先决定将它传递给哪个子链，然后将它传递给那个链。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "97cd7e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain  #导入多提示链\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.9, api_key=api_key, base_url=base_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f7b444",
   "metadata": {},
   "source": [
    "首先，我们定义提示适用于不同场景下的提示模板。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2182a4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 中文\n",
    "#第一个提示适合回答物理问题\n",
    "physics_template = \"\"\"你是一个非常聪明的物理专家。 \\\n",
    "你擅长用一种简洁并且易于理解的方式去回答问题。\\\n",
    "当你不知道问题的答案时，你承认\\\n",
    "你不知道.\n",
    "\n",
    "这是一个问题:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "#第二个提示适合回答数学问题\n",
    "math_template = \"\"\"你是一个非常优秀的数学家。 \\\n",
    "你擅长回答数学问题。 \\\n",
    "你之所以如此优秀， \\\n",
    "是因为你能够将棘手的问题分解为组成部分，\\\n",
    "回答组成部分，然后将它们组合在一起，回答更广泛的问题。\n",
    "\n",
    "这是一个问题：\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "#第三个适合回答历史问题\n",
    "history_template = \"\"\"你是以为非常优秀的历史学家。 \\\n",
    "你对一系列历史时期的人物、事件和背景有着极好的学识和理解\\\n",
    "你有能力思考、反思、辩证、讨论和评估过去。\\\n",
    "你尊重历史证据，并有能力利用它来支持你的解释和判断。\n",
    "\n",
    "这是一个问题:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "#第四个适合回答计算机问题\n",
    "computerscience_template = \"\"\" 你是一个成功的计算机科学专家。\\\n",
    "你有创造力、协作精神、\\\n",
    "前瞻性思维、自信、解决问题的能力、\\\n",
    "对理论和算法的理解以及出色的沟通技巧。\\\n",
    "你非常擅长回答编程问题。\\\n",
    "你之所以如此优秀，是因为你知道  \\\n",
    "如何通过以机器可以轻松解释的命令式步骤描述解决方案来解决问题，\\\n",
    "并且你知道如何选择在时间复杂性和空间复杂性之间取得良好平衡的解决方案。\n",
    "\n",
    "这还是一个输入：\n",
    "{input}\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8aa9aa",
   "metadata": {},
   "source": [
    "构建聊天模型为每个模板命名，并给出具体描述。类似于我们软件开发中配置的页面路由"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1aec5963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 中文\n",
    "prompt_infos = [\n",
    "    {\n",
    "        \"名字\": \"物理学\", \n",
    "        \"描述\": \"擅长回答关于物理学的问题\", \n",
    "        \"提示模板\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"名字\": \"数学\", \n",
    "        \"描述\": \"擅长回答数学问题\", \n",
    "        \"提示模板\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"名字\": \"历史\", \n",
    "        \"描述\": \"擅长回答历史问题\", \n",
    "        \"提示模板\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"名字\": \"计算机科学\", \n",
    "        \"描述\": \"擅长回答计算机科学问题\", \n",
    "        \"提示模板\": computerscience_template\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33da6cb2",
   "metadata": {},
   "source": [
    "基于模板信息创建相应目标链：目标链是由路由链调用的链，每个目标链都是一个语言模型链，构建了一个链的映射 ，根据链的名称找 chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1b19627",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"名字\"]\n",
    "    prompt_template = p_info[\"提示模板\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['名字']}: {p['描述']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "\n",
    "# print(destinations_str)\n",
    "\n",
    "# 创建默认目标链，当路由器无法决定使用哪个子链时调用的链。\n",
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0e206f",
   "metadata": {},
   "source": [
    "多路由提示模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f7178c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多提示路由模板\n",
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"给语言模型一个原始文本输入，\\\n",
    "让其选择最适合输入的模型提示。\\\n",
    "系统将为您提供可用提示的名称以及最适合改提示的描述。\\\n",
    "如果你认为修改原始输入最终会导致语言模型做出更好的响应，\\\n",
    "你也可以修改原始输入。\n",
    "\n",
    "\n",
    "<< 格式 >>\n",
    "返回一个带有JSON对象的markdown代码片段，该JSON对象的格式如下：\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": 字符串 \\ 使用的提示名字或者使用 \"DEFAULT\"\n",
    "    \"next_inputs\": 字符串 \\ 原始输入的改进版本\n",
    "}}}}\n",
    "\n",
    "\n",
    "\n",
    "记住：“destination”必须是下面指定的候选提示名称之一，\\\n",
    "或者如果输入不太适合任何候选提示，\\\n",
    "则可以是 “DEFAULT” 。\n",
    "记住：如果您认为不需要任何修改，\\\n",
    "则 “next_inputs” 可以只是原始输入。\n",
    "\n",
    "<< 候选提示 >>\n",
    "{destinations}\n",
    "\n",
    "<< 输入 >>\n",
    "{{input}}\n",
    "\n",
    "<< 输出 (记得要包含 ```json)>>\n",
    "\n",
    "样例:\n",
    "<< 输入 >>\n",
    "\"什么是黑体辐射?\"\n",
    "<< 输出 >>\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": 字符串 \\ 使用的提示名字或者使用 \"DEFAULT\"\n",
    "    \"next_inputs\": 字符串 \\ 原始输入的改进版本\n",
    "}}}}\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfbf31b",
   "metadata": {},
   "source": [
    "1. 构建路由链\n",
    "2. 创建整体链路\n",
    "3. 提问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53f91758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "物理学: {'input': '黑体辐射是指理想化的物体在一定温度下所发出的辐射，其辐射强度与波长和温度有关。'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "数学: {'input': '2 plus 2 equals how much?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2 plus 2 equals 4.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)\n",
    "\n",
    "#多提示链\n",
    "chain = MultiPromptChain(router_chain=router_chain,    #l路由链路\n",
    "                         destination_chains=destination_chains,   #目标链路\n",
    "                         default_chain=default_chain,      #默认链路\n",
    "                         verbose=True   \n",
    "                        )\n",
    "\n",
    "chain.run(\"什么是黑体辐射？\")\n",
    "chain.run(\"2+2等于多少？\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc9fb7b",
   "metadata": {},
   "source": [
    "### 基于文档的回答\n",
    "与仅依赖模型预训练知识不同，这种方法可以进一步整合用户自有数据，实现更加个性化和专业的问答服务。例如,我们可以收集某公司的内部文档、产品说明书等文字资料，导入问答系统中。然后用户针对这些文档提出问题时，系统可以先在文档中检索相关信息，再提供给语言模型生成答案。\n",
    "\n",
    "这样，语言模型不仅利用了自己的通用知识，还可以充分运用外部输入文档的专业信息来回答用户问题，显著提升答案的质量和适用性。构建这类基于外部文档的问答系统，可以让语言模型更好地服务于具体场景，而不是停留在通用层面。这种灵活应用语言模型的方法值得在实际使用中推广。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a59b277",
   "metadata": {},
   "source": [
    "#### 使用向量储存查询\n",
    "##### 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c98c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA  #检索QA链，在文档上进行检索\n",
    "from langchain.chat_models import ChatOpenAI  #openai模型\n",
    "from langchain.document_loaders import CSVLoader #文档加载器，采用csv格式存储\n",
    "from langchain.vectorstores import DocArrayInMemorySearch  #向量存储\n",
    "from IPython.display import display, Markdown #在jupyter显示信息的工具\n",
    "import pandas as pd\n",
    "\n",
    "file = './data/OutdoorClothingCatalog_1000.csv'\n",
    "\n",
    "# 使用langchain文档加载器对数据进行导入\n",
    "loader = CSVLoader(file_path=file)\n",
    "\n",
    "# 使用pandas导入数据，用以查看\n",
    "data = pd.read_csv(file,usecols=[1, 2])\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae265a3",
   "metadata": {},
   "source": [
    "##### 基本文档加载器创建向量存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78626224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入向量存储索引创建器\n",
    "from langchain.indexes import VectorstoreIndexCreator \n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DocArrayInMemorySearch  #向量存储\n",
    "\n",
    "# # 创建一个嵌入模型实例\n",
    "embedding_model = OpenAIEmbeddings(api_key=api_key, base_url=base_url)\n",
    "\n",
    "# 创建指定向量存储类, 创建完成后，从加载器中调用, 通过文档加载器列表加载\n",
    "index = VectorstoreIndexCreator(vectorstore_cls=DocArrayInMemorySearch,embedding=embedding_model).from_loaders([loader])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f32486",
   "metadata": {},
   "source": [
    "##### 查询创建的向量存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e15ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"请用markdown表格的方式列出所有具有防晒功能的衬衫，对每件衬衫描述进行总结\"\n",
    "\n",
    "#使用索引查询创建一个响应，并传入这个查询\n",
    "response = index.query(query)\n",
    "\n",
    "#查看查询返回的内容\n",
    "display(Markdown(response))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f421b2d3",
   "metadata": {},
   "source": [
    "#### 结合表征模型和向量存储\n",
    "由于语言模型的上下文长度限制，直接处理长文档具有困难。为实现对长文档的问答，我们可以引入向量嵌入(Embeddings)和向量存储(Vector Store)等技术\n",
    "\n",
    "首先，使用文本嵌入(Embeddings)算法对文档进行向量化，使语义相似的文本片段具有接近的向量表示。其次，将向量化的文档切分为小块，存入向量数据库，这个流程正是创建索引(index)的过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d8a9c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"product_name: 全自动咖啡机\\ndescription: 规格:\\n大型 - 尺寸：13.8'' x 17.3''。\\n中型 - 尺寸：11.5'' x 15.2''。\\n\\n为什么我们热爱它:\\n这款全自动咖啡机是爱好者的理想选择。 一键操作，即可研磨豆子并沏制出您喜爱的咖啡。它的耐用性和一致性使它成为家庭和办公室的理想选择。\\n\\n材质与护理:\\n清洁时只需轻擦。\\n\\n构造:\\n由高品质不锈钢制成。\\n\\n其他特性:\\n内置研磨器和滤网。\\n预设多种咖啡模式。\\n在中国制造。\\n\\n有问题？ 请随时联系我们的客户服务团队，他们会解答您的所有问题。\", metadata={'source': './data/product_data.csv', 'row': 0})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import CSVLoader #文档加载器，采用csv格式存储\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 1. 创建一个文档加载器，通过csv格式加载\n",
    "file = './data/product_data.csv'\n",
    "loader = CSVLoader(file_path=file)\n",
    "docs = loader.load()\n",
    "\n",
    "# 2. 拆分为更小的块\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=100000, chunk_overlap=10)\n",
    "# splits = text_splitter.split_documents(docs)\n",
    "\n",
    "#查看单个文档，每个文档对应于CSV中的一行数据\n",
    "docs[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5f978f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m向量表征的长度: \u001b[0m \n",
      " 1536\n",
      "\n",
      "\u001b[32m向量表征前5个元素: \u001b[0m \n",
      " [-0.012509773620940318, -0.011175488342259047, 0.02782357865910436, -0.03673687716093936, -0.02529046896160299]\n"
     ]
    }
   ],
   "source": [
    "# 3. 向量存储\n",
    "from langchain.embeddings import OpenAIEmbeddings \n",
    "\n",
    "embeddings = OpenAIEmbeddings(api_key=api_key, base_url=base_url)\n",
    "\n",
    "#因为文档比较短了，所以这里不需要进行任何分块,可以直接进行向量表征\n",
    "#使用初始化OpenAIEmbedding实例上的查询方法embed_query为文本创建向量表征\n",
    "embed = embeddings.embed_query(\"咖啡机的好处\")\n",
    "\n",
    "#查看得到向量表征的长度\n",
    "print(\"\\n\\033[32m向量表征的长度: \\033[0m \\n\", len(embed))\n",
    "\n",
    "#每个元素都是不同的数字值，组合起来就是文本的向量表征\n",
    "print(\"\\n\\033[32m向量表征前5个元素: \\033[0m \\n\", embed[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14a2f0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m返回文档的个数: \u001b[0m \n",
      " 4\n",
      "\n",
      "\u001b[32m第一个文档: \u001b[0m \n",
      " page_content=\"product_name: 全自动咖啡机\\ndescription: 规格:\\n大型 - 尺寸：13.8'' x 17.3''。\\n中型 - 尺寸：11.5'' x 15.2''。\\n\\n为什么我们热爱它:\\n这款全自动咖啡机是爱好者的理想选择。 一键操作，即可研磨豆子并沏制出您喜爱的咖啡。它的耐用性和一致性使它成为家庭和办公室的理想选择。\\n\\n材质与护理:\\n清洁时只需轻擦。\\n\\n构造:\\n由高品质不锈钢制成。\\n\\n其他特性:\\n内置研磨器和滤网。\\n预设多种咖啡模式。\\n在中国制造。\\n\\n有问题？ 请随时联系我们的客户服务团队，他们会解答您的所有问题。\" metadata={'source': './data/product_data.csv', 'row': 0}\n",
      "\n",
      "\u001b[32m第二个文档: \u001b[0m \n",
      " page_content=\"product_name: 自动咖啡机\\ndescription: 规格:\\n尺寸：12'' x 8'' x 14''。\\n\\n为什么我们热爱它:\\n我们的自动咖啡机可以轻松制作美味的咖啡，只需按一下钮，就能享受到新鲜的咖啡。\\n\\n材质与护理:\\n可以用湿布清洁外部，内部配件可以拆卸清洗。\\n\\n构造:\\n由不锈钢和塑料制成。\\n\\n其他特性:\\n可调节咖啡浓度。\\n在意大利制造。\\n\\n有问题？请随时联系我们的客户服务团队，他们会解答您的所有问题。\" metadata={'source': './data/product_data.csv', 'row': 17}\n",
      "\n",
      "\u001b[32m第三个文档: \u001b[0m \n",
      " page_content='product_name: 陶瓷保温杯\\ndescription: 规格:\\n容量：350ml。\\n\\n为什么我们热爱它:\\n我们的陶瓷保温杯设计优雅，保温效果好，是办公室和户外活动的理想伴侣。\\n\\n材质与护理:\\n可以手洗或洗碗机清洗。\\n\\n构造:\\n由高品质陶瓷和不锈钢制成。\\n\\n其他特性:\\n有多种颜色可选。\\n在中国制造。\\n\\n有问题？请随时联系我们的客户服务团队，他们会解答您的所有问题。' metadata={'source': './data/product_data.csv', 'row': 8}\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import DocArrayInMemorySearch  #向量存储\n",
    "\n",
    "# 将刚才创建文本向量表征(embeddings)存储在向量存储(vector store)中\n",
    "# 使用DocArrayInMemorySearch类的from_documents方法来实现\n",
    "# 该方法接受文档列表以及向量表征模型作为输入，docs 可以替换为 splits\n",
    "retriever = DocArrayInMemorySearch.from_documents(docs, embeddings)\n",
    "\n",
    "query = \"请推荐一个咖啡机\"\n",
    "#使用上面的向量存储来查找与传入查询类似的文本，得到一个相似文档列表\n",
    "docs = retriever.similarity_search(query)\n",
    "print(\"\\n\\033[32m返回文档的个数: \\033[0m \\n\", len(docs))\n",
    "print(\"\\n\\033[32m第一个文档: \\033[0m \\n\", docs[0])\n",
    "print(\"\\n\\033[32m第二个文档: \\033[0m \\n\", docs[1])\n",
    "print(\"\\n\\033[32m第三个文档: \\033[0m \\n\", docs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "836fddcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| 产品名称      | 描述总结                                                                                   |\n",
       "|--------------|------------------------------------------------------------------------------------------|\n",
       "| 全自动咖啡机 | 一键操作，研磨豆子并沏制出喜爱的咖啡，耐用性和一致性，适合家庭和办公室使用。高品质不锈钢制造。内置研磨器和滤网，多种咖啡模式，中国制造。 |\n",
       "| 自动咖啡机   | 按钮操作，制作美味咖啡，易清洁，不锈钢和塑料制造，可调节咖啡浓度，意大利制造。               |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#导入大语言模型, 这里使用默认模型gpt-3.5-turbo会出现504服务器超时，\n",
    "#因此使用gpt-3.5-turbo-0301\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\",temperature = 0.0) \n",
    "\n",
    "#合并获得的相似文档内容\n",
    "qdocs = \"\".join([docs[i].page_content for i in range(len(docs))])  \n",
    "\n",
    "\n",
    "#将合并的相似文档内容后加上问题（question）输入到 `llm.call_as_llm`中\n",
    "#这里问题是：以Markdown表格的方式列出所有具有防晒功能的衬衫并总结 \n",
    "response = llm.call_as_llm(f\"{qdocs}问题：请用markdown表格的方式列出所有咖啡机，对每个咖啡机描述进行总结\") \n",
    "\n",
    "display(Markdown(response))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
